---
title: "DelphinID North East Atlantic"
description: "delphinID classifier for the North East Atlantic - processes detected clicks and whistle contours to determine 7 delphinid species"
image: ./delphinID_NEAtlantic/dolphin_whistles_clicks.png
categories: [dolphin]
format: html
---

## Introduction

[delphinID](https://github.com/tristankleyn/which.dolphin/tree/main) models are deep convolutional neural networks (CNNs) trained in Python Tensorflow 2.18.0 to automatically classify detections of delphinid whistles and clicks to species by latent patterns in average low-frequency power spectra calculated across groups, or frames, of detections. Separate models for classifying based on either whistle or click detections output predictions intended to used as a feature vector for an event classifier, which predicts species based on information from both whistles and clicks. Cross-validated testing estimates delphinID to classify events with average accuracy ranging from 80% for Delphinus delphis to 92% for Lagenorhynchus albirostris.

![The Shiu and Palmer right whale classifier running in PAMGuard](./delphinID_NEAtlantic/PAMGuard_delphinID_gif.gif)

## Species

1.  Atlantic white-sided dolphin (Lagenorhynchus acutus)

2.  Common bottlenose dolphin (Tursiops truncatus)

3.  Killer whale (Orcinus orca)

4.  Long-finned pilot whale (Globicephala melas)

5.  Risso's dolphin (Grampus griseus)

6.  Short-beaked common dolphin (Delphinus delphis)

7.  White-beaked dolphin (Lagenorhynchus albirostris)

## Reference

Paper in prep.

## Model

Click and whistle models can be found on Zenodo. [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14578299.svg)](https://doi.org/10.5281/zenodo.14578299)

delphinID does not require raw sound data; instead it process detected PAMGuard whistle contours and click detections. Both whistle and click results can then be further combined in an [R shiny app]() to increase the accuracy of results.

An example settings file is located here. As well as the usual setting the location of the database, binary store and sound files, users also need to open both deep learning modules e.g. *Settings-\>Raw deep learning classifier_clicks* and select the deep learning models on their local machine. The configuration will then detect whistle contours and clicks from raw sound data, passing the detections to both deep learning modules with results saved in the PAMGuard database. Also note that delphinID can run in viewer mode if whisltes and/or click detections are part of the data model.
